{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s9pPT09myo"
      },
      "source": [
        "# AICUP2023_Spring_PathologicalVoice\n",
        "\n",
        "https://tbrain.trendmicro.com.tw/Competitions/Details/27\n",
        "\n",
        "多模態病理嗓音分類競賽"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoGzm6XMViVB"
      },
      "source": [
        "## Step 1: Get the training set from Google Drive\n",
        "\n",
        "https://drive.google.com/file/d/1GvW2YMpBaEfPeEMbUPUpaRfauwNpymeH/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ht36HDdV1LYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qkCHN19mJy"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install --upgrade --no-cache-dir gdown\n",
        "gdown https://drive.google.com/uc?id=1GvW2YMpBaEfPeEMbUPUpaRfauwNpymeH\n",
        "unzip train.zip\n",
        "rm train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awOOJEwSgQJd"
      },
      "outputs": [],
      "source": [
        "!ls -l ./train/*.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m971p6-WDCT"
      },
      "source": [
        "## Step 2: Audio to Spectrogram images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc7DsDc6UJEQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "sound_path =\"./train/training_voice_data/*.wav\"\n",
        "image_path =\"./train/\" \n",
        "files= glob.glob(sound_path)\n",
        "for i, file_path in enumerate(files):\n",
        "  path, filename = os.path.split(file_path)\n",
        "  pre, ext = os.path.splitext(filename)\n",
        "  spectroimage = pre + \".png\"\n",
        "  outputfile = os.path.join(image_path, spectroimage)\n",
        "  # Load audio\n",
        "  cmdstr=f'ffmpeg -i {file_path} -f wav - | ffmpeg -i - -filter_complex \"showspectrumpic=s=260x260:mode=separate:legend=disabled\" -c:v png -f image2pipe - | ffmpeg -y -i - {outputfile}'\n",
        "  subprocess.run(cmdstr, shell=True)\n",
        "print(len(files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiNTv0lCsgvN"
      },
      "outputs": [],
      "source": [
        "!ls ./train/*.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOiqDp7_8rR"
      },
      "source": [
        "## Step 3: Import python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bSelgZ8fV0a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C7Zbd4WfZ29"
      },
      "outputs": [],
      "source": [
        "device_name=torch.cuda.get_device_name(0)\n",
        "print(f\"Using GPU {device_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMbij8TFfmIQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSlY2Jkfm4N"
      },
      "source": [
        "## Step 4: read the training CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf4x7wc-foiW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"./train/training datalist.csv\")\n",
        "print(df_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sGibr5NgZ-W"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfAUSO8Ogh6t"
      },
      "outputs": [],
      "source": [
        "train_files = df_train.iloc[:,0].values\n",
        "train_labels = df_train.iloc[:,3].values-1\n",
        "print(train_labels[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1SY9F1Ag90N"
      },
      "outputs": [],
      "source": [
        "type(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeUW3sTvgopI"
      },
      "source": [
        "## Step 5: Show statistics of training images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkomuDA-grTS"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "g = sns.countplot(x=train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNfBwzssh3va"
      },
      "source": [
        "## Step 6: Choose one of CNN models \n",
        "\n",
        "### EfficientNet B0 to B7\n",
        "\n",
        "__Model-EfficientNet__\n",
        "\n",
        "https://pytorch.org/hub/nvidia_deeplearningexamples_efficientnet/\n",
        "\n",
        "|  Base model | resolution  | Base model | resolution  |\n",
        "|---|---|---|---|\n",
        "| EfficientNetB0  | 224  | EfficientNetB4  | 380  |\n",
        "| EfficientNetB1  | 240  | EfficientNetB5  | 456  |\n",
        "| EfficientNetB2  | 260  | EfficientNetB6  | 528  |\n",
        "| EfficientNetB3  | 300  | EfficientNetB7  | 600  |\n",
        "\n",
        "### 也可以試其他的models\n",
        "https://pytorch.org/vision/stable/models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcegsFRnh6XV"
      },
      "outputs": [],
      "source": [
        "num_classes=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-UzuZ5Ch-K4"
      },
      "outputs": [],
      "source": [
        "#modelfile = None\n",
        "modelfile = \"pv-EnB2-70.pth\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWHp02FPiArj"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "model=models.efficientnet_b2(num_classes=num_classes)\n",
        "if modelfile != None: model.load_state_dict(torch.load(modelfile))\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4O4qk7wiGKj"
      },
      "source": [
        "## Step 7: Instancing a dataloader \n",
        "* Transforms\n",
        "* CustomDataset\n",
        "* dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8255-E_iHLW"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "pretrained_size = 240\n",
        "pretrained_means = [0.485, 0.456, 0.406]\n",
        "pretrained_stds= [0.229, 0.224, 0.225]\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = pretrained_means, std = pretrained_stds)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDHQ9_SSiQYI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image \n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, images_folder, transform = None):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.df.iloc[index]['ID']+\".png\"\n",
        "        label = self.df.iloc[index]['Disease category']-1\n",
        "        image = Image.open(os.path.join(self.images_folder, filename))\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQMx7iAMipyH"
      },
      "source": [
        "## Step 8: Set up a train dataloader with a custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6YwF3wSiqTm"
      },
      "outputs": [],
      "source": [
        "batches = 48\n",
        "imgdir= \"train\" \n",
        "csvfile = \"./train/training datalist.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bga_x1niiznq"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(csvfile, imgdir, train_transform)\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=batches, shuffle=True)\n",
        "print(f\"Total images={len(train_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKNSf6Ci2pO"
      },
      "source": [
        "## Step 9: total_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNL6dyQyi3FW"
      },
      "outputs": [],
      "source": [
        "total_batch=len(train_dataset)//batches + 1\n",
        "print(total_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP0NpSTfi6gD"
      },
      "source": [
        "## Step 10: Set the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLtVEVjoi58R"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXnVBT9uHgab"
      },
      "source": [
        "## Step 11: Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhLfSHOUi6Cn"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46go1CYki_nO"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (batch_images, batch_labels) in enumerate(train_dataloader):\n",
        "    # Zero your gradients for every batch!\n",
        "    optimizer.zero_grad()\n",
        "    inputs = batch_images.cuda()\n",
        "    labels = batch_labels.cuda()\n",
        "    # Make predictions for this batch\n",
        "    outputs  = model(inputs)\n",
        "    \n",
        "    # Compute the loss and its gradients\n",
        "    cost = loss(outputs , labels)\n",
        "    cost.backward()\n",
        "    # Adjust learning weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}] Loss: {cost.item():.4f}')\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {cost.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk_v-fQRHtCt"
      },
      "source": [
        "### more epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-i46HVmBmID"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (batch_images, batch_labels) in enumerate(train_dataloader):\n",
        "    # Zero your gradients for every batch!\n",
        "    optimizer.zero_grad()\n",
        "    inputs = batch_images.cuda()\n",
        "    labels = batch_labels.cuda()\n",
        "    # Make predictions for this batch\n",
        "    outputs  = model(inputs)\n",
        "    \n",
        "    # Compute the loss and its gradients\n",
        "    cost = loss(outputs , labels)\n",
        "    cost.backward()\n",
        "    # Adjust learning weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], lter [{i+1}/{total_batch}] Loss: {cost.item():.4f}')\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {cost.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD8Hfhc3jflY"
      },
      "source": [
        "## Step 12: Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMHvjoRWjgCF"
      },
      "outputs": [],
      "source": [
        "outputfile = \"pv-EnB2-70.pth\" \n",
        "torch.save(model.state_dict(), outputfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnXL3wY7jm-f"
      },
      "source": [
        "## Step 13: Check training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYd2BP20jneP"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = pretrained_means, std = pretrained_stds)\n",
        "])\n",
        "batches =120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tlgRpVXjoyn"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset(csvfile, imgdir, test_transform)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=batches, shuffle=False)\n",
        "print(f\"Total images={len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ig78h2gjqbT"
      },
      "outputs": [],
      "source": [
        "classes=[0,1,2,3,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCD_53VPjrak"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_predictions= np.zeros(len(train_labels))\n",
        "train_outputs  = np.zeros((len(train_labels),num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_predictions[:10])"
      ],
      "metadata": {
        "id": "zbT7eLN_Ke7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8GSEifzjtkR"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "model.eval()\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    total_batch = len(test_dataset)//batches\n",
        "    for i, (batch_images, batch_labels) in enumerate(test_dataloader):\n",
        "      images = batch_images.cuda()\n",
        "      labels = batch_labels.cuda()\n",
        "      outputs = model(images)\n",
        "      _, predictions = torch.max(outputs, 1)\n",
        "      train_predictions[i*batches:(i+1)*batches] = predictions.cpu()\n",
        "      train_outputs[i*batches:(i+1)*batches, :]=F.softmax(outputs, dim=1).cpu()\n",
        "      if (i+1) % 10 == 0:\n",
        "          print(f'lter [{i+1}/{total_batch}]')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_predictions[:10])"
      ],
      "metadata": {
        "id": "_NPuSN4rMVuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_outputs[:10, :])"
      ],
      "metadata": {
        "id": "HWwQoQLee2RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqRsaVexju4x"
      },
      "outputs": [],
      "source": [
        "train_results=train_predictions.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SwWuKbljwEe"
      },
      "outputs": [],
      "source": [
        "print(train_labels[:10])\n",
        "print(train_results[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iJJwcXyjxN0"
      },
      "outputs": [],
      "source": [
        "print(train_predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 從這裡加xgboost"
      ],
      "metadata": {
        "id": "Dck2wME0fP7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "# 建立 XGBClassifier 模型\n",
        "xgboostModel = XGBClassifier(n_estimators=100, learning_rate= 0.3)"
      ],
      "metadata": {
        "id": "HsryCSF_fZ3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 將空值填0\n",
        "df_train['PPD'] = df_train['PPD'].fillna(0)\n",
        "df_train['Voice handicap index - 10'] = df_train['Voice handicap index - 10'].fillna(0)\n",
        "\n",
        "# 正規化過大的數值\n",
        "df_train['Age'] = df_train['Age'] / 50\n",
        "df_train['Voice handicap index - 10'] = df_train['Voice handicap index - 10'] / 40"
      ],
      "metadata": {
        "id": "OdER0ByCff2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols=[1, 2]+[x for x in range(4, 28)]\n",
        "print(cols)"
      ],
      "metadata": {
        "id": "xOHpymhRfmQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=df_train.iloc[:, cols]\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "id": "UDlZxsrCfooF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOHnnYzThtS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd.concat([X_train, pd.DataFrame(train_outputs)], axis=1)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "XeFujo9zf8Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.to_numpy()\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "PDvRwmzXiHla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用訓練資料訓練模型\n",
        "y_train = df_train.iloc[:,3].values-1\n",
        "xgboostModel.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AiNSyD3LiyRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用訓練資料預測分類\n",
        "train_predictions = xgboostModel.predict(X_train)"
      ],
      "metadata": {
        "id": "TgsJ8vahjCI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOnol2L_jy92"
      },
      "outputs": [],
      "source": [
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "# collect the correct predictions for each class\n",
        "for label, prediction in zip(train_labels, train_predictions):\n",
        "    if label == prediction:\n",
        "        correct_pred[classes[label]] += 1\n",
        "    total_pred[classes[label]] += 1\n",
        "    \n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname} is {accuracy:.1f} %')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xbtcsVPj0gG"
      },
      "source": [
        "## Step 14: Analyze training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU1mbgUZj1nA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion=confusion_matrix(train_labels, train_predictions)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZ8utkm9m2a"
      },
      "source": [
        "## 測試資料集\n",
        "https://drive.google.com/file/d/12ARQ6z8HciF7UcKNtsZLOsmprKQQoYbm/view?usp=share_link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuHYwvjqj6qD"
      },
      "source": [
        "## Step 21: Load the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RsaGwTbGUII"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "gdown https://drive.google.com/uc?id=12ARQ6z8HciF7UcKNtsZLOsmprKQQoYbm\n",
        "unzip public.zip\n",
        "rm public.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjcLv01wJFGm"
      },
      "source": [
        "## Step 22: Audio to Spectrogram images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zYCbjhaKAiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "sound_path =\"./public/test_data_public/*.wav\"\n",
        "image_path =\"./public/\" \n",
        "files= glob.glob(sound_path)\n",
        "for i, file_path in enumerate(files):\n",
        "  path, filename = os.path.split(file_path)\n",
        "  pre, ext = os.path.splitext(filename)\n",
        "  spectroimage = pre + \".png\"\n",
        "  outputfile = os.path.join(image_path, spectroimage)\n",
        "  # Load audio\n",
        "  cmdstr=f'ffmpeg -i {file_path} -f wav - | ffmpeg -i - -filter_complex \"showspectrumpic=s=260x260:mode=separate:legend=disabled\" -c:v png -f image2pipe - | ffmpeg -y -i - {outputfile}'\n",
        "  subprocess.run(cmdstr, shell=True)\n",
        "print(len(files))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G47e4oT3GolJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30IoP8haLP09"
      },
      "outputs": [],
      "source": [
        "!ls ./public/*.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rDIT20NLUYi"
      },
      "source": [
        "## Step 24: read the test CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKCoFsBYLc0k"
      },
      "outputs": [],
      "source": [
        "!ls -l ./public/*.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_UB-Kb1LWk0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(\"./public/test_datalist_public.csv\")\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmqLG9CQLlKK"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUTqse5lNc7J"
      },
      "source": [
        "## Step 26：CustomTestDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RM-xCf0NgW_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image \n",
        "class CustomTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, images_folder, transform = None):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.images_folder = images_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.df.iloc[index]['ID']+\".png\"\n",
        "        label = -1\n",
        "        image = Image.open(os.path.join(self.images_folder, filename))\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue39YST1L17h"
      },
      "source": [
        "## Step 27: Instancing a dataloader \n",
        "* Transforms\n",
        "* CustomDataset\n",
        "* dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5BdNrKGL5kR"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = pretrained_means, std = pretrained_stds)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN96eZfHMT77"
      },
      "outputs": [],
      "source": [
        "batches = 50\n",
        "imgdir= \"public\" \n",
        "csvfile = \"./public/test_datalist_public.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkr_1KHlMMbr"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomTestDataset(csvfile, imgdir, test_transform)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=batches, shuffle=False)\n",
        "print(f\"Total images={len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VjjcAxMM4OV"
      },
      "outputs": [],
      "source": [
        "classes=[0,1,2,3,4]\n",
        "test_predictions = np.zeros(len(test_dataset))\n",
        "test_outputs = np.zeros((len(test_dataset),num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VExy7K_GM-8N"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    total_batch = len(test_dataset)//batches\n",
        "    for i, (batch_images, batch_labels) in enumerate(test_dataloader):\n",
        "      images = batch_images.cuda()\n",
        "      outputs = model(images)\n",
        "      _, predictions = torch.max(outputs, 1)\n",
        "      test_predictions[i*batches:(i+1)*batches] = predictions.cpu()\n",
        "      test_outputs[i*batches:(i+1)*batches, :] = F.softmax(outputs, dim=1).cpu()\n",
        "      if (i+1) % 10 == 0:\n",
        "          print(f'lter [{i+1}/{total_batch}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu1tKYW9Rqcy"
      },
      "source": [
        "## Step 31: Check test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgpf4H3zR30N"
      },
      "outputs": [],
      "source": [
        "test_predictions=test_predictions.astype(int)\n",
        "test_predictions[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 挿入XGBoost"
      ],
      "metadata": {
        "id": "qqtLWFEokk-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(\"./public/test_datalist_public.csv\")\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "Pbg0Dm2ok0iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 將空值填0\n",
        "df_test['PPD'] = df_test['PPD'].fillna(0)\n",
        "df_test['Voice handicap index - 10'] = df_test['Voice handicap index - 10'].fillna(0)\n",
        "\n",
        "# 正規化過大的數值\n",
        "df_test['Age'] = df_test['Age'] / 50\n",
        "df_test['Voice handicap index - 10'] = df_test['Voice handicap index - 10'] / 40"
      ],
      "metadata": {
        "id": "dGvXMubAloyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols=[x for x in range(1, 27)]\n",
        "print(cols)"
      ],
      "metadata": {
        "id": "Zise_bB1lsgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=df_test.iloc[:, cols]"
      ],
      "metadata": {
        "id": "3JnZS4ial4OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_outputs.shape"
      ],
      "metadata": {
        "id": "lx5wdqUWkZfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=pd.concat([X_test, pd.DataFrame(test_outputs)], axis=1)\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "z8bm9ClKlkqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用訓練資料預測分類\n",
        "y_test = xgboostModel.predict(X_test)"
      ],
      "metadata": {
        "id": "uwchfODHmC9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:10])"
      ],
      "metadata": {
        "id": "fLeNHD45mHEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3ZF4nK9TE2I"
      },
      "source": [
        "## Step 32: Load the template for test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjXm36XZSB5l"
      },
      "outputs": [],
      "source": [
        "csvfile2 = \"./public/submission_template_public.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Egx5t2ZTDCH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_out = pd.read_csv(csvfile2, header = None)\n",
        "print(df_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlQa-mKnTdfw"
      },
      "outputs": [],
      "source": [
        "df_out.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgZ91rhhTmaX"
      },
      "source": [
        "## Step 33: Fill the test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spjsY29WTzhX"
      },
      "outputs": [],
      "source": [
        "df_out[1]=y_test+1\n",
        "df_out.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtPa9nxRWV4I"
      },
      "outputs": [],
      "source": [
        "df_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yOd7frJUmjE"
      },
      "outputs": [],
      "source": [
        "df_out.to_csv(\"esemble-b2-htchu-0515.csv\", index=False, header=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}